{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll begin learning how to build chatbots in Python by writing two functions to build the simplest bot possible: EchoBot. EchoBot just responds by replying with the same message it receives.\n",
    "\n",
    "In this exercise, you'll define a function that responds to a user's message. In the next exercise, you'll complete EchoBot by writing a function to send a message to the bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that responds to a user's message: respond\n",
    "def respond(message):\n",
    "    # Concatenate the user's message to the end of a standard bot respone\n",
    "    bot_message = \"I can hear you! You said: \" + message\n",
    "    # Return the result\n",
    "    return bot_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having written your respond() function, you'll now define a function called send_message() with a single parameter message which logs the message and the bot's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello\n",
      "BOT : I can hear you! You said: hello\n"
     ]
    }
   ],
   "source": [
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "# Send a message to the bot\n",
    "send_message(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're going to leave simple EchoBot behind and create a bot which can answer simple questions such as \"What's your name?\" and \"What's today's weather?\"\n",
    "\n",
    "You'll use a dictionary with these questions as keys, and the correct responses as values.\n",
    "\n",
    "This means the bot will only respond correctly if the message matches exactly, which is a big limitation. In later exercises you will create much more robust solutions.\n",
    "\n",
    "The send_message function has already been defined for you, as well as the bot_template and user_template variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "name = \"PrateekG\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary with the predefined responses\n",
    "responses = {\n",
    "  \"what's your name?\": \"my name is {0}\".format(name),\n",
    "  \"what's today's weather?\": \"the weather is {0}\".format(weather),\n",
    "  \"default\": \"default message\"\n",
    "}\n",
    "\n",
    "# Return the matching response if there is one, default otherwise\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return the matching message\n",
    "        bot_message = responses[message]\n",
    "    else:\n",
    "        # Return the \"default\" message\n",
    "        bot_message = responses[\"default\"]\n",
    "    return bot_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can get a little boring hearing the same old answers over and over. In this exercise, you'll add some variation. If you ask your bot how it's feeling, it may equally well respond with \"oh I'm great!\" as with \"I'm very sad today\".\n",
    "\n",
    "Here, you'll use the random module - specifically random.choice(ls) - which randomly selects an element from a list ls.\n",
    "\n",
    "A dictionary called responses, which maps each message to a list of possible responses, has been defined for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the random module\n",
    "import random\n",
    "\n",
    "name = \"PrateekG\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary containing a list of responses for each message\n",
    "responses = {\n",
    "  \"what's your name?\": [\n",
    "      \"my name is {0}\".format(name),\n",
    "      \"they call me {0}\".format(name),\n",
    "      \"I go by {0}\".format(name)\n",
    "   ],\n",
    "  \"what's today's weather?\": [\n",
    "      \"the weather is {0}\".format(weather),\n",
    "      \"it's {0} today\".format(weather)\n",
    "    ],\n",
    "  \"default\": [\"default message\"]\n",
    "}\n",
    "\n",
    "# Use random.choice() to choose a matching response\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return a random matching response\n",
    "        bot_message = random.choice(responses[message])\n",
    "    else:\n",
    "        # Return a random \"default\" response\n",
    "        bot_message = random.choice(responses[\"default\"])\n",
    "    return bot_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking questions is a great way to create an engaging conversation. Here, you'll create the very first hint of ELIZA's famous personality, by responding to statements with a question and responding to questions with answers.\n",
    "\n",
    "A dictionary of responses with \"question\" and \"statement\" as keys, and lists of appropriate responses as values has already been defined for you. Explore this in the Shell with responses.keys() and responses[\"question\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : what's today's weather?\n",
      "BOT : I don't know :(\n",
      "USER : what's today's weather?\n",
      "BOT : I don't know :(\n",
      "USER : I love building chatbots\n",
      "BOT : can you back that up?\n",
      "USER : I love building chatbots\n",
      "BOT : oh wow!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def respond(message):\n",
    "    # Check for a question mark\n",
    "    if message.endswith('?'):\n",
    "        # Return a random question\n",
    "        return random.choice(responses[\"question\"])\n",
    "    # Return a random statement\n",
    "    return random.choice(responses[\"statement\"])\n",
    "\n",
    "responses={'question': [\"I don't know :(\", 'you tell me!'],\n",
    "           'statement': ['tell me more!',\n",
    "           'why do you think that?',\n",
    "           'how long have you felt this way?',\n",
    "           'I find that extremely interesting',\n",
    "           'can you back that up?',\n",
    "           'oh wow!',\n",
    "           ':)']}\n",
    "\n",
    "# Send messages ending in a question mark\n",
    "send_message(\"what's today's weather?\")\n",
    "send_message(\"what's today's weather?\")\n",
    "\n",
    "# Send messages which don't end with a question mark\n",
    "send_message(\"I love building chatbots\")\n",
    "send_message(\"I love building chatbots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The really clever thing about ELIZA is the way the program appears to understand what you told it, by occasionally including phrases uttered by the user in its responses.\n",
    "\n",
    "In this exercise, you will match messages against some common patterns and extract phrases using re.search(). A dictionary called rules has already been defined, which matches the following patterns:\n",
    "\n",
    "\"do you think (.*)\"\n",
    "\"do you remember (.*)\"\n",
    "\"I want (.*)\"\n",
    "\"if (.*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yes .. and?', None)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "rules={'I want (.*)': ['What would it mean if you got {0}',\n",
    "                       'Why do you want {0}',\n",
    "                       \"What's stopping you from getting {0}\"],\n",
    "                       'do you remember (.*)': ['Did you think I would forget {0}',\n",
    "                       \"Why haven't you been able to forget {0}\",\n",
    "                       'What about {0}',\n",
    "                       'Yes .. and?'],\n",
    "      'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
    "      'if (.*)': [\"Do you really think it's likely that {0}\",\n",
    "                  'Do you wish that {0}','What do you think about {0}','Really--if {0}']}\n",
    "\n",
    "# Define match_rule()\n",
    "def match_rule(rules, message):\n",
    "    response, phrase = \"default\", None\n",
    "    \n",
    "    # Iterate over the rules dictionary\n",
    "    for pattern, responses in rules.items():\n",
    "        # Create a match object\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            # Choose a random response\n",
    "            response = random.choice(responses)\n",
    "            if '{0}' in response:\n",
    "                phrase = match.group(1)\n",
    "    # Return the response and phrase\n",
    "    return response, phrase\n",
    "\n",
    "# Test match_rule\n",
    "print(match_rule(rules, \"do you remember your last birthday\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make responses grammatically coherent, you'll want to transform the extracted phrases from first to second person and vice versa. In English, conjugating verbs is easy, and simply swapping \"I\" and 'you', \"my\" and \"your\" works in most cases.\n",
    "\n",
    "In this exercise, you'll define a function called replace_pronouns() which uses re.sub() to map \"me\" and \"my\" to \"you\" and \"your\" (and vice versa) in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your last birthday\n",
      "when me went to florida\n",
      "i had your own castle\n"
     ]
    }
   ],
   "source": [
    "# Define replace_pronouns()\n",
    "def replace_pronouns(message):\n",
    "\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return re.sub('me', 'you', message)\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return re.sub('my', 'your', message)\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return re.sub('your', 'my', message)\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return re.sub('you', 'me', message)\n",
    "\n",
    "    return message\n",
    "\n",
    "print(replace_pronouns(\"my last birthday\"))\n",
    "print(replace_pronouns(\"when you went to Florida\"))\n",
    "print(replace_pronouns(\"I had my own castle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're going to put it all together and experience the magic! The match_rule(), send_message(), and replace_pronouns() functions have already been defined, and the rules dictionary is available in your workspace.\n",
    "\n",
    "Your job here is to write a function called respond() with a single argument message which creates an appropriate response to be handled by send_message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : do you remember your last birthday\n",
      "BOT : Did you think I would forget my last birthday\n",
      "USER : do you think humans should be worried about AI\n",
      "BOT : No chance\n",
      "USER : I want a robot friend\n",
      "BOT : What's stopping you from getting a robot friend\n",
      "USER : what if you could be anything you wanted\n",
      "BOT : Do you really think it's likely that me could be anything me wanted\n"
     ]
    }
   ],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Call match_rule\n",
    "    response, phrase = match_rule(rules, message)\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns in the phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Include the phrase in the response\n",
    "        response = response.format(phrase)\n",
    "    return response\n",
    "\n",
    "# Send the messages\n",
    "send_message(\"do you remember your last birthday\")\n",
    "send_message(\"do you think humans should be worried about AI\")\n",
    "send_message(\"I want a robot friend\")\n",
    "send_message(\"what if you could be anything you wanted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll begin by implementing a very simple way to recognise intents - just looking for the presence of keywords.\n",
    "\n",
    "A dictionary keywords has already been defined. It has the intents \"greet\", \"goodbye\", and \"thankyou\" as keys, and lists of keywords as the corresponding values. For example, keywords[\"greet\"] is set to \"[\"hello\",\"hi\",\"hey\"].\n",
    "\n",
    "Also defined is a second dictionary, responses, indicating how the bot should respond to each of these intents. It also has a default response with the key \"default\".\n",
    "\n",
    "The function send_message(), along with the bot and user templates have also already been defined. Your job in this exercise is to create a dictionary with the intents as keys and regex objects as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'goodbye': re.compile('bye|farewell'), 'greet': re.compile('hello|hi|hey'), 'thankyou': re.compile('thank|thx')}\n"
     ]
    }
   ],
   "source": [
    "keywords={'goodbye': ['bye', 'farewell'],\n",
    "         'greet': ['hello', 'hi', 'hey'],\n",
    "         'thankyou': ['thank', 'thx']}\n",
    "\n",
    "responses={'default': 'default message',\n",
    "         'goodbye': 'goodbye for now',\n",
    "         'greet': 'Hello you! :)',\n",
    "         'thankyou': 'you are very welcome'}\n",
    "\n",
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(keys))\n",
    "\n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your patterns dictionary created, it's now time to define a function to find the intent of a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello!\n",
      "BOT : Hello you! :)\n",
      "USER : bye byeee\n",
      "BOT : goodbye for now\n",
      "USER : thanks very much!\n",
      "BOT : you are very welcome\n"
     ]
    }
   ],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent\n",
    "\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! Your bot can now respond to messages even when they don't match exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you'll use another simple method, this time for finding a person's name in a sentence such as \"hello, my name is David Copperfield\".\n",
    "\n",
    "You'll look for the keywords \"name\" or \"call(ed)\", and find capitalized words using regex and assume those are names. Your job in this exercise is to define a find_name() function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : my name is Prateek Gupta\n",
      "BOT : Hello, Prateek Gupta!\n",
      "USER : call me PrateekG\n",
      "BOT : Hello, Prateek G!\n",
      "USER : People call me PrateekG\n",
      "BOT : Hello, People Prateek G!\n"
     ]
    }
   ],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile('name|call')\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile('[A-Z]{1}[a-z]*')\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is Prateek Gupta\")\n",
    "send_message(\"call me PrateekG\")\n",
    "send_message(\"People call me PrateekG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word vectors with spaCy\n",
    "In this exercise you'll get your first experience with word vectors! You're going to use the ATIS dataset, which contains thousands of sentences from real people interacting with a flight booking system.\n",
    "\n",
    "The user utterances are available in the list sentences, and the corresponding intents in labels.\n",
    "\n",
    "Your job is to create a 2D array X with as many rows as there are sentences in the dataset, where each row is a vector describing that sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.dropbox.com/s/3lxl9jsbw0j7h8a/atis.pkl?dl=0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'atis.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4ce91c76d7ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0matisfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mw2idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels2idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentences'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-4ce91c76d7ba>\u001b[0m in \u001b[0;36matisfull\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0matisfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dropbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPREFIX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'atis.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-4ce91c76d7ba>\u001b[0m in \u001b[0;36mload_dropbox\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mdownload_dropbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#f = gzip.open(filename,'rb')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'atis.pkl'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "PREFIX = os.getenv('ATISDATA', '')\n",
    "\n",
    "def atisfull():\n",
    "    f = load_dropbox(PREFIX + 'atis.pkl')\n",
    "    \n",
    "    try:\n",
    "        train_set, test_set, dicts = pickle.load(f)\n",
    "    except UnicodeDecodeError:\n",
    "        train_set, test_set, dicts = pickle.load(f, encoding='latin1')\n",
    "    return train_set, test_set, dicts\n",
    "\n",
    "def load_dropbox(filename):\n",
    "    if not isfile(filename):\n",
    "        #download('http://www-etud.iro.umontreal.ca/~mesnilgr/atis/'+filename)\n",
    "        download_dropbox()\n",
    "    #f = gzip.open(filename,'rb')\n",
    "    f = open(filename,'rb')\n",
    "    return f\n",
    "\n",
    "def download_dropbox():\n",
    "    ''' \n",
    "    download from drop box in the meantime\n",
    "    '''\n",
    "    print('Downloading data from https://www.dropbox.com/s/3lxl9jsbw0j7h8a/atis.pkl?dl=0')\n",
    "    os.system('wget -O atis.pkl https://www.dropbox.com/s/3lxl9jsbw0j7h8a/atis.pkl?dl=0')\n",
    "\n",
    "\n",
    "train_set, valid_set, dicts = atisfull()\n",
    "w2idx, labels2idx = dicts['sentences'], dicts['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (384) into shape (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-502a7f37d9fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# Save the document's .vector attribute to the corresponding row in X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (384) into shape (0)"
     ]
    }
   ],
   "source": [
    "sentences=[' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning',\n",
    " ' what flights are available from pittsburgh to baltimore on thursday morning',\n",
    " ' what is the arrival time in san francisco for the 755 am flight leaving washington',\n",
    " ' cheapest airfare from tacoma to orlando',\n",
    " ' round trip fares from pittsburgh to philadelphia under 1000 dollars',\n",
    " ' i need a flight tomorrow from columbus to minneapolis',\n",
    " ' what kind of aircraft is used on a flight from cleveland to dallas',\n",
    " ' show me the flights from pittsburgh to los angeles on thursday',\n",
    " ' all flights from boston to washington',\n",
    " ' what kind of ground transportation is available in denver',\n",
    " ' show me the flights from dallas to san francisco',\n",
    " ' show me the flights from san diego to newark by way of houston',\n",
    " ' what is the cheapest flight from boston to bwi',\n",
    " ' all flights to baltimore after 6 pm',\n",
    " ' show me the first class fares from boston to denver',\n",
    " ' show me the ground transportation in denver',\n",
    " ' all flights from denver to pittsburgh leaving after 6 pm and before 7 pm',\n",
    " ' i need information on flights for tuesday leaving baltimore for dallas dallas to boston and boston to baltimore',\n",
    " ' please give me the flights from boston to pittsburgh on thursday of next week',\n",
    " ' i would like to fly from denver to pittsburgh on united airlines',\n",
    " ' show me the flights from san diego to newark',\n",
    " ' please list all first class flights on united from denver to baltimore',\n",
    " ' what kinds of planes are used by american airlines',\n",
    " \" i'd like to have some information on a ticket from denver to pittsburgh and atlanta\",\n",
    " \" i'd like to book a flight from atlanta to denver\",\n",
    " ' which airline serves denver pittsburgh and atlanta',\n",
    " \" show me all flights from boston to pittsburgh on wednesday of next week which leave boston after 2 o'clock pm\",\n",
    " ' atlanta ground transportation',\n",
    " ' i also need service from dallas to boston arriving by noon',\n",
    " ' show me the cheapest round trip fare from baltimore to dallas']\n",
    "\n",
    "\n",
    "labels=['atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_flight_time',\n",
    " 'atis_airfare',\n",
    " 'atis_airfare',\n",
    " 'atis_flight',\n",
    " 'atis_aircraft',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_ground_service',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_airfare',\n",
    " 'atis_ground_service',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_flight',\n",
    " 'atis_aircraft',\n",
    " 'atis_airfare',\n",
    " 'atis_flight',\n",
    " 'atis_airline',\n",
    " 'atis_flight',\n",
    " 'atis_ground_service',\n",
    " 'atis_flight',\n",
    " 'atis_airfare']\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "# Load the spacy model: nlp\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx,:] = doc.vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Intent classification with sklearn\n",
    "An array X containing vectors describing each of the sentences in the ATIS dataset has been created for you, along with a 1D array y containing the labels. The labels are integers corresponding to the intents in the dataset. For example, label 0 corresponds to the intent atis_flight.\n",
    "\n",
    "Now, you'll use the scikit-learn library to train a classifier on this same dataset. Specifically, you will fit and evaluate a support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a support vector classifier\n",
    "clf = SVC(C=1)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "n_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        n_correct += 1\n",
    "\n",
    "print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spaCy's entity recogniser\n",
    "In this exercise you'll use spaCy's built-in entity recognizer to extract names, dates, and organizations from search queries. The spaCy library has been imported for you, and it's English model has been loaded as nlp.\n",
    "\n",
    "Your job is to define a function called extract_entities() which takes in a single argument message and returns a dictionary with the included entity types as keys, and the extracted entities as values. The included entity types are contained in a list called include_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': '2010', 'ORG': 'Google', 'PERSON': 'Mary'}\n",
      "{'DATE': '1999', 'ORG': 'MIT', 'PERSON': None}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "# Define included entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Load the spacy model: nlp\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning roles using spaCy's parser\n",
    "In this exercise you'll use spaCy's powerful syntax parser to assign roles to the entities in your users' messages. To do this, you'll define two functions, find_parent_item() and assign_colors(). In doing so, you'll use a parse tree to assign roles, similar to how Alan did in the video.\n",
    "\n",
    "Recall that you can access the ancestors of a word using its .ancestors attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entity_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d7584cf6ec9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Assign the colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0massign_colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-d7584cf6ec9f>\u001b[0m in \u001b[0;36massign_colors\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Check for \"color\" entities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mentity_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"color\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;31m# Find the parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mfind_parent_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'entity_type' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the document\n",
    "doc = nlp(\"let's see that jacket in red and some blue jeans\")\n",
    "\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in word.ancestors:\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(parent) == \"item\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in doc:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"color\":\n",
    "            # Find the parent\n",
    "            item =  find_parent_item(word)\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "assign_colors(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasa NLU\n",
    "In this exercise you'll use Rasa NLU to create an interpreter, which parses incoming user messages and returns a set of entities. Your job is to train an interpreter using the MITIE entity recognition model in rasa NLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rasa_nlu.converters import load_data\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid training data file / folder specified. Could not locate the resource 'C:\\Users\\prateek1.gupta\\training_data.json'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\rasa_nlu\\converters.py\u001b[0m in \u001b[0;36mresolve_data_files\u001b[1;34m(resource_name)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_find_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\rasa_nlu\\utils\\__init__.py\u001b[0m in \u001b[0;36mrecursively_find_files\u001b[1;34m(resource_name)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not locate the resource '{}'.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not locate the resource 'C:\\Users\\prateek1.gupta\\training_data.json'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e02a6bb727aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Load the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./training_data.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Create an interpreter by training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\rasa_nlu\\converters.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(resource_name, language, fformat)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;34m\"\"\"Loads training data from disk. If no format is provided, the format will be guessed based on the files.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresolve_data_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfformat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\rasa_nlu\\converters.py\u001b[0m in \u001b[0;36mresolve_data_files\u001b[1;34m(resource_name)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_find_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid training data file / folder specified. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid training data file / folder specified. Could not locate the resource 'C:\\Users\\prateek1.gupta\\training_data.json'."
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.converters import load_data\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "# Create args dictionary\n",
    "args = {\"pipeline\": \"spacy_sklearn\"}\n",
    "\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUConfig(cmdline_args=args)\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Load the training data\n",
    "training_data = load_data(\"./training_data.json\")\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Try it out\n",
    "print(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You just trained an intent and entity recogniser without having to create any arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-efficient entity recognition\n",
    "Most systems for extracting entities from text are built to extract 'Universal' things like names, dates, and places. But you probably don't have enough training data for your bot to make these systems perform well!\n",
    "\n",
    "In this exercise, you'll activate the MITIE entity recogniser inside rasa to extract restaurants-related entities using a very small amount of training data. A dictionary args has already been defined for you, along with a training_data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-596ed1028db3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Create an interpreter by training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Parse some messages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "pipeline = [\n",
    "    \"nlp_spacy\",\n",
    "    \"tokenizer_spacy\",\n",
    "    \"ner_crf\"\n",
    "]\n",
    "\n",
    "# Create a config that uses this pipeline\n",
    "config = RasaNLUConfig(cmdline_args={\"pipeline\": pipeline})\n",
    "\n",
    "# Create a trainer that uses this config\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Parse some messages\n",
    "print(interpreter.parse(\"show me Chinese food in the centre of town\"))\n",
    "print(interpreter.parse(\"I want an Indian restaurant in the west\"))\n",
    "print(interpreter.parse(\"are there any good pizza places in the center?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good! You just built a custom entity recogniser with Rasa NLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL statements in Python\n",
    "It's time to begin writing SQL queries! In this exercise, your job is to run a query against the hotels database to find all the expensive hotels in the south. The connection to the database has been created for you, along with a cursor c.\n",
    "\n",
    "As Alan described in the video, you should be careful about SQL injection. Here, you'll pass parameters the safe way: As an extra tuple argument to the .execute() method. This ensures malicious code can't be injected into your query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    create_connection(\"E:/sqlite/db/hotels.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_data(conn, insert_data_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(insert_data_sql)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    database = \"E:/sqlite/db/hotels.db\"\n",
    " \n",
    "    sql_create_projects_table = \"\"\" CREATE TABLE IF NOT EXISTS hotels (\n",
    "                                        name text NOT NULL,\n",
    "                                        price text,\n",
    "                                        area text,\n",
    "                                        star integer\n",
    "                                    ); \"\"\"\n",
    " \n",
    " \n",
    "    # create a database connection\n",
    "    conn = create_connection(database)\n",
    "    if conn is not None:\n",
    "        # create projects table\n",
    "        create_table(conn, sql_create_projects_table)\n",
    "    else:\n",
    "        print(\"Error! cannot create the database connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    database = \"E:/sqlite/db/hotels.db\"\n",
    "    \n",
    "    sql_insert_projects_table = \"\"\" insert into hotels(name,price,area,star) values('Bills Burgers','hi','east',3); \"\"\"\n",
    " \n",
    " \n",
    "    # create a database connection\n",
    "    conn = create_connection(database)\n",
    "    if conn is not None:\n",
    "        # create projects table\n",
    "        insert_data(conn, sql_insert_projects_table)\n",
    "    else:\n",
    "        print(\"Error! cannot insert into the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table hotels has no column named star\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open connection to DB\n",
    "conn = sqlite3.connect('E:/sqlite/db/hotels.db')\n",
    "\n",
    "# Create a cursor\n",
    "c = conn.cursor()\n",
    "\n",
    "# Define area and price\n",
    "area, price = \"east\", \"hi\"\n",
    "t = (area, price)\n",
    "\n",
    "# Execute the query\n",
    "c.execute('SELECT * FROM hotels WHERE area=? AND price=?', t)\n",
    "\n",
    "# Print the results\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import sqlite3\n",
    "import sqlite3\n",
    "\n",
    "# Open connection to DB\n",
    "conn = sqlite3.connect('hotels.db')\n",
    "\n",
    "# Create a cursor\n",
    "c = conn.cursor()\n",
    "\n",
    "# Define area and price\n",
    "area, price = \"south\", \"hi\"\n",
    "t = (area, price)\n",
    "\n",
    "# Execute the query\n",
    "c.execute('SELECT * FROM hotels WHERE area=? AND price=?', t)\n",
    "\n",
    "# Print the results\n",
    "print(c.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating queries from parameters\n",
    "Now you're going to implement a more powerful function for querying the hotels database. The goal is to take arguments that can later be specified by other parts of your code.\n",
    "\n",
    "Specifically, your job here is to define a find_hotels() function which takes a single argument - a dictionary of column names and values - and returns a list of matching hotels from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define find_hotels()\n",
    "def find_hotels(params):\n",
    "    # Create the base query\n",
    "    query = 'SELECT * FROM hotels'\n",
    "    # Add filter clauses for each of the parameters\n",
    "    if len(params) > 0:\n",
    "        filters = [\"{}=?\".format(k) for k in params]\n",
    "        query += \" WHERE \" + \" and \".join(filters)\n",
    "    # Create the tuple of values\n",
    "    t = tuple(params.values())\n",
    "    \n",
    "    # Open connection to DB\n",
    "    conn = sqlite3.connect('hotels.db')\n",
    "    # Create a cursor\n",
    "    c = conn.cursor()\n",
    "    # Execute the query\n",
    "    c.execute(query, t)\n",
    "    # Return the results\n",
    "    return c.fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super! You've now got a function that can find matching hotels for any area and price range combination. You'll practice using it in the next exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the dictionary of column names and values\n",
    "params = {\"area\":\"south\",\"price\":\"lo\"}\n",
    "\n",
    "# Find the hotels that match the parameters\n",
    "print(find_hotels(params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SQL from natural language\n",
    "Now you'll write a respond() function which can handle messages like \"I want an expensive hotel in the south of town\" and respond appropriately according to the number of matching results in a database. This is important functionality for any database-backed chatbot.\n",
    "\n",
    "Your find_hotels() function from the previous exercises has already been defined for you, along with a rasa NLU interpreter object which can handle hotel queries and a list of responses, which you can explore in the Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Initialize an empty params dictionary\n",
    "    params = {}\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find hotels that match the dictionary\n",
    "    results = find_hotels(params)\n",
    "    # Get the names of the hotels and index of the response\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Select the nth element of the responses array\n",
    "    return responses[n].format(*names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! You've built a chatbot that can interpret the results of your hotel DB queries. Now, call the respond() function with the message \"I want an expensive hotel in the south of town\". Place it inside a call to print() so that you can see the response of your bot in the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Initialize an empty params dictionary\n",
    "    params = {}\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find hotels that match the dictionary\n",
    "    results = find_hotels(params)\n",
    "    # Get the names of the hotels and index of the response\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Select the nth element of the responses array\n",
    "    return responses[n].format(*names)\n",
    "\n",
    "print(respond(\"I want an expensive hotel in the south of town\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refining your search\n",
    "Now you'll write a bot that allows users to add filters incrementally, in case they don't specify all of their preferences in one message.\n",
    "\n",
    "To do this, initialize an empty dictionary params outside of your respond() function (unlike inside the function, like in the previous exercise). Your respond() function will take in this dictionary as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a respond function, taking the message and existing params as input\n",
    "def respond(message, params):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find the hotels\n",
    "    results = find_hotels(params)\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results), 3)\n",
    "    # Return the appropriate response\n",
    "    return responses[n].format(*names), params\n",
    "\n",
    "# Initialize params dictionary\n",
    "params = {}\n",
    "\n",
    "# Pass the messages to the bot\n",
    "for message in [\"I want an expensive hotel\", \"in the north of town\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params = respond(message, params)\n",
    "    print(\"BOT: {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic negation\n",
    "Quite often you'll find your users telling you what they don't want - and that's important to understand! In general, negation is a difficult problem in NLP. Here we'll take a very simple approach that works for many cases.\n",
    "\n",
    "A list of tests called tests has been defined for you. Explore it in the Shell - you'll find that each test is a tuple consisting of:\n",
    "\n",
    "A string containing a message with entities\n",
    "A dictionary containing the entities as keys, and a Boolean saying whether they are negated as the key\n",
    "Your job is to define a function called negated_ents() which looks for negated entities in a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tests=[(\"no I don't want to be in the south\", {'south': False}),\n",
    " ('no it should be in the south', {'south': True}),\n",
    " ('no in the south not the north', {'north': False, 'south': True}),\n",
    " ('not north', {'north': False})]\n",
    "\n",
    "# Define negated_ents()\n",
    "def negated_ents(phrase):\n",
    "    # Extract the entities using keyword matching\n",
    "    ents = [e for e in [\"south\", \"north\"] if e in phrase]\n",
    "    # Find the index of the final character of each entity\n",
    "    ends = sorted([phrase.index(e) + len(e) for e in ents])\n",
    "    # Initialise a list to store sentence chunks\n",
    "    chunks = []\n",
    "    # Take slices of the sentence up to and including each entitiy\n",
    "    start = 0\n",
    "    for end in ends:\n",
    "        chunks.append(phrase[start:end])\n",
    "        start = end\n",
    "    result = {}\n",
    "    # Iterate over the chunks and look for entities\n",
    "    for chunk in chunks:\n",
    "        for ent in ents:\n",
    "            if ent in chunk:\n",
    "                # If the entity is preceeded by a negation, give it the key False\n",
    "                if \"not\" in chunk or \"n't\" in chunk:\n",
    "                    result[ent] = False\n",
    "                else:\n",
    "                    result[ent] = True\n",
    "    return result  \n",
    "\n",
    "# Check that the entities are correctly assigned as True or False\n",
    "for test in tests:\n",
    "    print(negated_ents(test[0]) == test[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering with excluded slots\n",
    "Now you're going to put together some of the ideas from previous exercises, and allow users to tell your bot about what they do and what they don't want, split across multiple messages.\n",
    "\n",
    "The negated_ents() function has already been defined for you. Additionally, a slightly tweaked version of the find_hotels() function, which accepts a neg_params dictionary in addition to a params dictionary, has been defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the respond function\n",
    "def respond(message,params,neg_params):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    ent_vals = [e[\"value\"] for e in entities]\n",
    "    # Look for negated entities\n",
    "    negated = negated_ents(message,ent_vals)\n",
    "    for ent in entities:\n",
    "        if ent[\"value\"] in negated and negated[ent[\"value\"]]:\n",
    "            neg_params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "        else:\n",
    "            params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "    # Find the hotels\n",
    "    results = find_hotels(params,neg_params)\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Return the correct response\n",
    "    return responses[n].format(*names), params, neg_params\n",
    "\n",
    "# Initialize params and neg_params\n",
    "params = {}\n",
    "neg_params = {}\n",
    "\n",
    "# Pass the messages to the bot\n",
    "for message in [\"I want a cheap hotel\", \"but not in the north of town\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params, neg_params = respond(message, params, neg_params)\n",
    "    print(\"BOT: {}\".format(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Your bot can now handle just about any sequence of requests, with positive or negative preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stateful bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form filling\n",
    "You'll often want your bot to guide users through a series of steps, such as when they're placing an order.\n",
    "\n",
    "In this exercise, you'll begin building a bot that lets users order coffee. They can choose between two types: Colombian, and Kenyan. If the user provides unexpected input, your bot will handle this differently depending on where they are in the flow.\n",
    "\n",
    "Your job here is to identify the appropriate state and next state based on the intents and response messages provided. For example, if the intent is \"order\", then the state changes from INIT to CHOOSE_COFFEE.\n",
    "\n",
    "A function send_message(policy, state, message) has already been defined for you. It takes the policy, the current state and message as arguments, and returns the new state as a result. Additionally, an interpret(message) function, similar to the one Alan described in the video, has been pre-defined for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the INIT state\n",
    "INIT = 0\n",
    "\n",
    "# Define the CHOOSE_COFFEE state\n",
    "CHOOSE_COFFEE = 1\n",
    "\n",
    "# Define the ORDERED state\n",
    "ORDERED = 2\n",
    "\n",
    "# Define the policy rules\n",
    "policy = {\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Columbian or Kenyan?\"),\n",
    "    (INIT, \"none\"): (INIT, \"I'm sorry - I'm not sure how to help you\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"none\"): (CHOOSE_COFFEE, \"I'm sorry - would you like Colombian or Kenyan?\"),\n",
    "}\n",
    "\n",
    "# Create the list of messages\n",
    "messages = [\n",
    "    \"I'd like to become a professional dancer\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"my favourite animal is a zebra\",\n",
    "    \"kenyan\"\n",
    "]\n",
    "\n",
    "# Call send_message() for each message\n",
    "state = INIT\n",
    "for message in messages:    \n",
    "    state = send_message(policy, state, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You just built your first chatbot with a state machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking contextual questions\n",
    "Sometimes your users need some help! They will have questions and expect the bot to help them.\n",
    "\n",
    "In this exercise, you'll allow users to ask the coffee bot to explain the steps to them. Like before, the answer they get will depend on where they are in the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the states\n",
    "INIT=0 \n",
    "CHOOSE_COFFEE=1\n",
    "ORDERED=2\n",
    "\n",
    "# Define the policy rules dictionary\n",
    "policy_rules = {\n",
    "    (INIT, \"ask_explanation\"): (INIT, \"I'm a bot to help you order coffee beans\"),\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Columbian or Kenyan?\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"ask_explanation\"): (CHOOSE_COFFEE, \"We have two kinds of coffee beans - the Kenyan ones make a slightly sweeter coffee, and cost $6. The Brazilian beans make a nutty coffee and cost $5.\")    \n",
    "}\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    for msg in messages:\n",
    "        state = send_message(state, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"what can you do for me?\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"what do you mean by that?\",\n",
    "    \"kenyan\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good work! Your bot can now modify its answers by considering context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with rejection\n",
    "What happens if you make a suggestion to your user, and they don't like it? Your bot will look really silly if it makes the same suggestion again right away.\n",
    "\n",
    "Here, you're going to modify your respond() function so that it accepts and returns 4 arguments:\n",
    "\n",
    "The user message as an argument, and the bot response as the first return value.\n",
    "A dictionary params including the entities the user has specified.\n",
    "A suggestions list. When passed to respond(), this should contain the suggestions made in the previous bot message. When returned by respond(), it should contain the current suggestions.\n",
    "An excluded list, which contains all of the results your user has already explicitly rejected.\n",
    "Your function should add the previous suggestions to the excluded list whenever it receives a \"deny\" intent. It should also filter out excluded suggestions from the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message, params, prev_suggestions, excluded):\n",
    "    # Interpret the message\n",
    "    parse_data = interpret(message)\n",
    "    # Extract the intent\n",
    "    intent = parse_data[\"intent\"][\"name\"]\n",
    "    # Extract the entities\n",
    "    entities = parse_data[\"entities\"]\n",
    "    # Add the suggestion to the excluded list if intent is \"deny\"\n",
    "    if intent == \"deny\":\n",
    "        excluded.extend(prev_suggestions)\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "    # Find matching hotels\n",
    "    results = [\n",
    "        r \n",
    "        for r in find_hotels(params, excluded) \n",
    "        if r[0] not in excluded\n",
    "    ]\n",
    "    # Extract the suggestions\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results), 3)\n",
    "    suggestions = names[:2]\n",
    "    return responses[n].format(*names), params, suggestions, excluded\n",
    "\n",
    "# Initialize the empty dictionary and lists\n",
    "params, suggestions, excluded = {}, [], []\n",
    "\n",
    "# Send the messages\n",
    "for message in [\"I want a mid range hotel\", \"no that doesn't work for me\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params, suggestions, excluded = respond(message, params, suggestions, excluded)\n",
    "    print(\"BOT: {}\".format(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pending actions I\n",
    "You can really improve the user experience of your bot by asking them simple yes or no questions. One easy way to handle these follow-ups is to define pending actions which get executed as soon as the user says \"yes\", and wiped if the user says \"no\".\n",
    "\n",
    "In this exercise, you're going to define a policy function which takes the intent as it's sole argument, and returns two values: The next action to take, and a pending action. The policy function should return this value when a \"yes\" intent is returned, and should wipe the pending actions if a \"no\" intent is returned.\n",
    "\n",
    "Here, the interpret(message) function has been defined for you such that if \"yes\" is in the message, \"affirm\" is returned, and if \"no\" is in the message, then \"deny\" is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define policy()\n",
    "def policy(intent):\n",
    "    # Return \"do_pending\" if the intent is \"affirm\"\n",
    "    if intent == \"affirm\":\n",
    "        return \"do_pending\", None\n",
    "    # Return \"Ok\" if the intent is \"deny\"\n",
    "    if intent == \"deny\":\n",
    "        return \"Ok\", None\n",
    "    if intent == \"order\":\n",
    "        return \"Unfortunately, the Kenyan coffee is currently out of stock, would you like to order the Brazilian beans?\", \"Alright, I've ordered that for you!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pending actions II\n",
    "Having defined your policy function, it's now time to write a send_message() function which takes both a pending action and a message as its arguments and leverages the policy function to determine the bot's response.\n",
    "\n",
    "Your policy(intent) function from the previous exercise has been pre-loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define send_message()\n",
    "def send_message(pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    action, pending_action = policy(interpret(message))\n",
    "    if action == 'do_pending' and pending is not None:\n",
    "        print(\"BOT : {}\".format(pending))\n",
    "    else:\n",
    "        print(\"BOT : {}\".format(action))\n",
    "    return pending_action\n",
    "    \n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        pending = send_message(pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"ok yes please\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pending state transitions\n",
    "You'll often need to briefly deviate from a flow, for example to authenticate a user, before returning.\n",
    "\n",
    "In these cases, it's often simpler - and easier to debug - to save some actions/states as pending rather than adding ever more complicated rules.\n",
    "\n",
    "Here, you're going to define a policy_rules dictionary, where the keys are tuples of the current state and the received intent, while the values are tuples of the next state, the bot's response, and a state for which to set a pending transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the states\n",
    "INIT=0\n",
    "AUTHED=1\n",
    "CHOOSE_COFFEE=2\n",
    "ORDERED=3\n",
    "\n",
    "# Define the policy rules\n",
    "policy_rules = {\n",
    "    (INIT, \"order\"): (INIT, \"you'll have to log in first, what's your phone number?\", AUTHED),\n",
    "    (INIT, \"number\"): (AUTHED, \"perfect, welcome back!\", None),\n",
    "    (AUTHED, \"order\"): (CHOOSE_COFFEE, \"would you like Columbian or Kenyan?\", None),    \n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\", None)\n",
    "}\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"555-12345\",\n",
    "    \"kenyan\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together I\n",
    "It's time to put everything together everything you've learned in the course by combining the coffee ordering bot with the eliza rules from chapter 1.\n",
    "\n",
    "To begin, you'll define a function called chitchat_response(), which calls the predefined function match_rule() from back in chapter 1. This returns a response if the message matched an eliza template, and otherwise, None.\n",
    "\n",
    "The eliza rules are contained in a dictionary called eliza_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eliza_rules = {'I want (.*)': ['What would it mean if you got {0}',\n",
    "  'Why do you want {0}',\n",
    "  \"What's stopping you from getting {0}\"],\n",
    " 'do you remember (.*)': ['Did you think I would forget {0}',\n",
    "  \"Why haven't you been able to forget {0}\",\n",
    "  'What about {0}',\n",
    "  'Yes .. and?'],\n",
    " 'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
    " 'if (.*)': [\"Do you really think it's likely that {0}\",\n",
    "  'Do you wish that {0}',\n",
    "  'What do you think about {0}',\n",
    "  'Really--if {0}']}\n",
    "\n",
    "# Define chitchat_response()\n",
    "def chitchat_response(message):\n",
    "    # Call match_rule()\n",
    "    response, phrase = match_rule(eliza_rules, message)\n",
    "    # Return none is response is \"default\"\n",
    "    if response == \"default\":\n",
    "        return None\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns of phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Calculate the response\n",
    "        response = response.format(phrase)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together II\n",
    "With your chitchat_response(message) function defined, the next step is to define a send_message() function which first calls chitchat_response(message), and only uses the coffee bot policy if there is no matching message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define send_message()\n",
    "def send_message(state, pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    response = chitchat_response(message)\n",
    "    if response is not None:\n",
    "        print(\"BOT : {}\".format(response))\n",
    "        return state, None\n",
    "    \n",
    "    # Calculate the new_state, response, and pending_state\n",
    "    new_state, response, pending_state = policy_rules[(state, interpret(message))]\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    if pending is not None:\n",
    "        new_state, response, pending_state = policy_rules[pending]\n",
    "        print(\"BOT : {}\".format(response))        \n",
    "    if pending_state is not None:\n",
    "        pending = (pending_state, interpret(message))\n",
    "    return new_state, pending\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"555-12345\",\n",
    "    \"do you remember when I ordered 1000 kilos by accident?\",\n",
    "    \"kenyan\"\n",
    "])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating text with neural networks\n",
    "In this final exercise of the course, you're going to generate text using a neural network trained on the scripts of every episode of The Simpsons. Specifically, you'll use a simplified version of the sample_text() function that Alan described in the video.\n",
    "\n",
    "It takes in two arguments, seed, and temperature. The seed argument is the initial sequence that the network uses to generate the subsequent text, while the temperature argument controls how risky the network is when generating text. At very low temperatures, it just repeats the most common combinations of letters, and at very high temperatures it generates complete gibberish. In order to ensure fast runtimes, the network in this exercise will only work for the subset of temperature values.\n",
    "\n",
    "After you finish this exercise, be sure to check out this tutorial by Alan in which he walks you through how to connect a chatbot to Facebook Messenger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feed the 'seed' text into the neural network\n",
    "seed = \"i'm gonna punch lenny in the back of the\"\n",
    "\n",
    "# Iterate over the different temperature values\n",
    "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(\"\\nGenerating text with riskiness : {}\\n\".format(temperature))\n",
    "    # Call the sample_text function\n",
    "    print(sample_text(seed, temperature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool! You just generated some text with a neural network. Scroll through the output to see the text generated with different values of the temperature parameter. And congratulations on completing the course! If you're itching to continue learning about chatbots, check out this tutorial by Alan in which you'll learn how to connect your bot to Facebook Messenger!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
